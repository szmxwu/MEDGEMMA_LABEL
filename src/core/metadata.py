# -*- coding: utf-8 -*-
"""
DICOM å…ƒæ•°æ®æå–æ¨¡å—ã€‚

è¯¥æ¨¡å—æä¾›ä» DICOM åŒ»å­¦å½±åƒæ–‡ä»¶ä¸­æå–å…ƒæ•°æ®å¹¶å¯¼å‡ºä¸º Excel çš„åŠŸèƒ½ã€‚
ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
- éå†åºåˆ—ç›®å½•ï¼Œæå– DICOM æ ‡ç­¾ä¿¡æ¯
- æ”¯æŒä¸åŒæ¨¡æ€ï¼ˆCTã€MRã€DRã€MGã€DX ç­‰ï¼‰çš„ç‰¹å®šå…³é”®å­—æå–
- å¤„ç†ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤è¯»å– DICOM æ–‡ä»¶
- å°†æå–çš„å…ƒæ•°æ®å¯¼å‡ºä¸ºç»“æ„åŒ–çš„ Excel æ–‡ä»¶ï¼ˆåŒ…å«æ±‡æ€»è¡¨å’Œè¯¦ç»†è¡¨ï¼‰
- é›†æˆ MR æ•°æ®æ¸…æ´—ç»“æœåˆ° Excel æŠ¥å‘Š

å…¸å‹ç”¨æ³•ï¼š
    from src.core.metadata import extract_dicom_metadata
    
    excel_path = extract_dicom_metadata(
        organized_dir="/path/to/organized",
        output_excel="/path/to/output.xlsx",
        get_keywords=lambda mod: ["PatientID", "StudyDate", ...],
        ...
    )
"""

from __future__ import annotations

import json
import os
import time
from typing import Callable, Dict, List, Optional, Tuple

import pandas as pd
import pydicom


def extract_dicom_metadata(
    organized_dir: str,
    output_excel: Optional[str],
    get_keywords: Callable[[str], List[str]],
    get_converted_files: Callable[[str], Tuple[List[str], Optional[str]]],
    assess_converted_file_quality: Callable[[str], int],
    assess_series_quality_converted: Callable[[List[str]], Dict],
    append_mr_cleaned_sheet: Callable[[pd.DataFrame, str], None],
) -> Optional[str]:
    """
    ä»å·²æ•´ç†çš„ DICOM ç›®å½•ä¸­æå–å…ƒæ•°æ®å¹¶ç”Ÿæˆ Excel æŠ¥å‘Šã€‚

    éå† organized_dir ä¸‹çš„æ‰€æœ‰åºåˆ—æ–‡ä»¶å¤¹ï¼Œè¯»å– DICOM æ–‡ä»¶çš„å…ƒæ•°æ®æ ‡ç­¾ï¼Œ
    æ ¹æ®ä¸åŒæ¨¡æ€æå–ç›¸åº”å…³é”®å­—ï¼Œè¯„ä¼°è½¬æ¢åæ–‡ä»¶çš„è´¨é‡ï¼Œå¹¶å°†ç»“æœå¯¼å‡ºä¸º
    Excel æ–‡ä»¶ï¼ˆåŒ…å« DICOM_Metadata å’Œ Series_Summary ä¸¤ä¸ªå·¥ä½œè¡¨ï¼‰ã€‚

    å‚æ•°:
        organized_dir: å·²æ•´ç†çš„ DICOM ç›®å½•è·¯å¾„ï¼Œæ¯ä¸ªå­æ–‡ä»¶å¤¹ä»£è¡¨ä¸€ä¸ªåºåˆ—
        output_excel: è¾“å‡º Excel æ–‡ä»¶è·¯å¾„ï¼Œè‹¥ä¸º None åˆ™è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        get_keywords: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶æ¨¡æ€å­—ç¬¦ä¸²ï¼ˆå¦‚ 'CT', 'MR'ï¼‰ï¼Œè¿”å›è¦æå–çš„ DICOM å…³é”®å­—åˆ—è¡¨
        get_converted_files: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶åºåˆ—è·¯å¾„ï¼Œè¿”å› (è½¬æ¢æ–‡ä»¶åˆ—è¡¨, é™„åŠ ä¿¡æ¯) å…ƒç»„
        assess_converted_file_quality: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶æ–‡ä»¶è·¯å¾„ï¼Œè¿”å›è´¨é‡è¯„åˆ†ï¼ˆ0=æ­£å¸¸ï¼Œ1=ä½è´¨é‡ï¼‰
        assess_series_quality_converted: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œè¿”å›è´¨é‡æ±‡æ€»å­—å…¸
        append_mr_cleaned_sheet: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ DataFrame å’Œ Excel è·¯å¾„ï¼Œç”¨äºæ·»åŠ  MR æ¸…æ´—ç»“æœ

    è¿”å›:
        ç”Ÿæˆçš„ Excel æ–‡ä»¶è·¯å¾„ï¼Œæå–å¤±è´¥åˆ™è¿”å› None
    """
    if output_excel is None:
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        output_excel = os.path.join(os.path.dirname(organized_dir), f"dicom_metadata_{timestamp}.xlsx")

    print("ğŸ“Š Extracting DICOM metadata...")

    all_metadata: List[Dict] = []

    for series_folder in os.listdir(organized_dir):
        series_path = os.path.join(organized_dir, series_folder)
        if not os.path.isdir(series_path):
            continue

        print(f"ğŸ“‚ Processing series: {series_folder}")

        converted_files, _ = get_converted_files(series_path)

        dicom_files: List[str] = []
        for file in os.listdir(series_path):
            filepath = os.path.join(series_path, file)
            if file.endswith('.dcm') and os.path.isfile(filepath):
                dicom_files.append(filepath)

        if not dicom_files:
            cache_path = os.path.join(series_path, "dicom_metadata_cache.json")
            if os.path.exists(cache_path):
                try:
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        cache = json.load(f)
                    cached_records = cache.get('records', [])
                    cached_modality = str(cache.get('modality', '')).upper()
                    sample_tags = cache.get('sample_tags') or {}
                    current_keywords = get_keywords(cached_modality) if cached_modality else []
                    read_all = cached_modality in ['DR', 'MG', 'DX']

                    if cached_records:
                        for record in cached_records:
                            for keyword in current_keywords:
                                if keyword not in record:
                                    record[keyword] = str(sample_tags.get(keyword, "")) if sample_tags else ""
                    elif sample_tags:
                        cached_records = [{
                            'SeriesFolder': series_folder,
                            'TotalFilesInSeries': 0,
                            'FilesReadForMetadata': 0,
                            'Modality': cached_modality
                        }]
                        for keyword in current_keywords:
                            cached_records[0][keyword] = str(sample_tags.get(keyword, ""))

                    if read_all:
                        converted_quality = [assess_converted_file_quality(p) for p in converted_files]
                        for idx, record in enumerate(cached_records):
                            record['Low_quality'] = converted_quality[idx] if idx < len(converted_quality) else 1
                            all_metadata.append(record)
                    else:
                        series_quality = assess_series_quality_converted(converted_files).get('low_quality', 1)
                        if cached_records:
                            cached_records[0]['Low_quality'] = series_quality
                            all_metadata.append(cached_records[0])
                    continue
                except Exception:
                    pass

            nifti_files = [f for f in os.listdir(series_path) if f.endswith(('.nii.gz', '.nii'))]
            if nifti_files:
                metadata = {
                    'SeriesFolder': series_folder,
                    'ConvertedToNIfTI': 'Yes',
                    'NIfTIFile': nifti_files[0],
                    'TotalFilesInSeries': 1
                }
                all_metadata.append(metadata)
            continue

        try:
            sample_file = dicom_files[0]
            dcm = pydicom.dcmread(sample_file, force=True)
            modality = getattr(dcm, 'Modality', '')
            need_read_all = modality in ['DR', 'MG', 'DX']

            current_keywords = get_keywords(modality)

            if need_read_all:
                print(f"   â„¹ï¸  Detected {modality} modality; will read all {len(dicom_files)} DICOM files")
                records: List[Dict] = []
                for idx, dicom_file in enumerate(dicom_files):
                    try:
                        dcm = pydicom.dcmread(dicom_file, force=True)
                        metadata = {
                            'SeriesFolder': series_folder,
                            'FileName': os.path.basename(dicom_file),
                            'FileIndex': idx + 1,
                            'TotalFilesInSeries': len(dicom_files)
                        }
                        for keyword in current_keywords:
                            try:
                                value = getattr(dcm, keyword, None)
                                if value is not None:
                                    if hasattr(value, '__len__') and not isinstance(value, str):
                                        if len(value) == 1:
                                            value = value[0]
                                        else:
                                            value = str(value)
                                    elif hasattr(value, 'value'):
                                        value = value.value
                                    metadata[keyword] = str(value)
                                else:
                                    metadata[keyword] = ""
                            except Exception:
                                metadata[keyword] = ""
                        records.append(metadata)
                    except Exception:
                        continue

                converted_quality = [assess_converted_file_quality(p) for p in converted_files]
                for idx, record in enumerate(records):
                    record['Low_quality'] = converted_quality[idx] if idx < len(converted_quality) else 1
                    all_metadata.append(record)

                    if (idx + 1) % 10 == 0:
                        print(f"      Processed {idx + 1}/{len(records)} files...")
            else:
                print(f"   â„¹ï¸  {modality} modality; reading representative file only")
                metadata = {
                    'SeriesFolder': series_folder,
                    'SampleFileName': os.path.basename(sample_file),
                    'TotalFilesInSeries': len(dicom_files),
                    'FilesReadForMetadata': 1
                }
                for keyword in current_keywords:
                    try:
                        value = getattr(dcm, keyword, None)
                        if value is not None:
                            if hasattr(value, '__len__') and not isinstance(value, str):
                                if len(value) == 1:
                                    value = value[0]
                                else:
                                    value = str(value)
                            elif hasattr(value, 'value'):
                                value = value.value
                            metadata[keyword] = str(value)
                        else:
                            metadata[keyword] = ""
                    except Exception:
                        metadata[keyword] = ""
                metadata['Low_quality'] = assess_series_quality_converted(converted_files).get('low_quality', 1)
                all_metadata.append(metadata)

        except Exception as e:
            print(f"     âŒ Failed processing series: {e}")
            continue

    if not all_metadata:
        print("âŒ No metadata extracted")
        return None

    try:
        df = pd.DataFrame(all_metadata)

        column_order: List[str] = []
        priority_columns = ['SeriesFolder', 'FileName', 'SampleFileName', 'FileIndex',
                            'TotalFilesInSeries', 'FilesReadForMetadata']
        for col in priority_columns:
            if col in df.columns:
                column_order.append(col)

        important_fields = ['PatientID', 'AccessionNumber', 'StudyDate', 'Modality',
                            'SeriesNumber', 'SeriesDescription', 'InstanceNumber', 'Rows', 'Columns']
        for field in important_fields:
            if field in df.columns and field not in column_order:
                column_order.append(field)

        for col in df.columns:
            if col not in column_order:
                column_order.append(col)

        df = df[column_order]

        with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='DICOM_Metadata', index=False)

            summary_data: List[Dict] = []
            for series_folder in df['SeriesFolder'].unique():
                series_df = df[df['SeriesFolder'] == series_folder]
                summary_row = {
                    'SeriesFolder': series_folder,
                    'FileCount': len(series_df),
                    'Modality': series_df['Modality'].iloc[0] if 'Modality' in series_df.columns else '',
                    'SeriesDescription': series_df['SeriesDescription'].iloc[0] if 'SeriesDescription' in series_df.columns else '',
                    'PatientID': series_df['PatientID'].iloc[0] if 'PatientID' in series_df.columns else '',
                    'AccessionNumber': series_df['AccessionNumber'].iloc[0] if 'AccessionNumber' in series_df.columns else '',
                    'StudyDate': series_df['StudyDate'].iloc[0] if 'StudyDate' in series_df.columns else ''
                }
                summary_data.append(summary_row)

            if summary_data:
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='Series_Summary', index=False)

            for sheet_name in writer.sheets:
                worksheet = writer.sheets[sheet_name]
                for column in worksheet.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except Exception:
                            pass
                    adjusted_width = min(max_length + 2, 50)
                    worksheet.column_dimensions[column_letter].width = adjusted_width

        total_files_read = len(df)
        dr_mg_dx_series = df[df['Modality'].isin(['DR', 'MG', 'DX'])]['SeriesFolder'].nunique() if 'Modality' in df.columns else 0

        print("âœ… Metadata extraction complete!")
        print(f"ğŸ“„ Excel file: {output_excel}")
        print(f"ğŸ“Š Total records: {total_files_read}")
        if dr_mg_dx_series > 0:
            print(f"ğŸ“‹ DR/MG/DX series count: {dr_mg_dx_series} (all files read)")

        append_mr_cleaned_sheet(df, output_excel)
        return output_excel

    except Exception as e:
        print(f"âŒ Failed saving Excel file: {e}")
        return None
